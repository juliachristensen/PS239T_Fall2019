---
title: "Structural Topic Modelling"
author: "PS239T"
date: "Spring 2018"
output: html_document
---

This unit gives a brief overview of the stm (structural topic model) package, written by Margaret Roberts, Brandon Stewart,and Dustin Tingley. Please read the vignette for more detail.

Structural topic modelling is a way to estimate a topic model that includes document-level meta-data. One can then see how topical prevalence changes according to that meta-data.

### Setup Environment and Load Data

First let's load our required packages.

```{r}
setwd("~/Desktop/PS239T/12_text-analysis") # YOUR DIRECTORY HERE
rm(list=ls())
library(stm)
library(dplyr)
```

## 0. Load Ddata

The data we'll be using for this unit consists of all articles about women published in the New York Times and Washington Post, 1980-2014. 

**NOTE** I downloaded these articles from Lexis Nexis and then used [this script](http://nealcaren.web.unc.edu/cleaning-up-lexisnexis-files/) to parse it into a csv

```{r}
# Load Data
women <- read.csv('Data/women-full.csv')
names(women)
```

Notice that we have the text of the articles, along with some metadata.

## 1. Preprocessing

STM has its own unique preprocessing functions. We're first going to create our own custom stop words (words to remove), containing country names.

```{r}
# Country custom stopwords
countries <- unique(women$COUNTRY_FINAL)
stopwords.country <- c(as.character(countries), "saudi", "german", "ese", "ian")
stopwords.country <- tolower(stopwords.country)
```

Now we'll follow STM's preprocessing procedure. Notice that we're going to use the `TEXT.NO.NOUN` column, which contains all the text of the articles without proper nouns (which I removed earlier)

```{r}
# Pre-process
temp<-textProcessor(documents=women$TEXT.NO.NOUN, metadata=women, customstopwords=stopwords.country)
meta<-temp$meta
vocab<-temp$vocab
docs<-temp$documents
out <- prepDocuments(docs, vocab, meta, lower.thresh=10)
docs<-out$documents
vocab<-out$vocab
meta <-out$meta
```

## 2. Estimate Model

We're now going to estimate a topic model with 15 topics by regressing topical prevalence on region, year, and publication covariates. I've included the code below but it takes a **long** time to finish. The second line of code loads the already-estimated model, which I've saved as an .RData object.

```{r}
# Uncomment to run -- it will take awhile! Take out the `max.em.its` argument to run to convergence.
# model <- stm(docs,vocab, 15, prevalence=~REGION+s(YEAR)+PUBLICATION, data=meta, seed = 15, max.em.its = 50)

# load the already-estimated model.
load("Data/stm.RData")
```

## 3. Explore the model

Let's see what our model came up with! 

- `topicQuality` plots topics on their coherence and exclusivity scores.
- `labelTopics` gives the top words for each topic. 
- `findThoughts` gives the top documents for each topic (the documents with the highest proportion of each topic)

I then use those to apply hand labels to each topic.

```{r}
# Topic Quality plot
topicQuality(model=model, documents=docs)

# Top Words
labelTopics(model)

# Example Docs
findThoughts(model,texts=meta$TITLE,n=3,topics=1:15)

# Hand Labels
labels = c("Business", "Sports", "Public Health", "Travel", "Fashion", "UN", "Sexual Assault", "Combat", "Women's Rights and Gender Equality", "Politics", "Profiles", "Human Interest", "Marriage & Family", "Religion", "Reproductive & Personal Health")

# Challenge - can you redo the plot to display the new labels? 

# YOUR CODE HERE
```

## 4. Analyze topics

We're now going to see how the topics compare in terms of their prevalence. 

```{r}
# Corpus Summary
plot.STM(model,type="summary",custom.labels=labels,main="")

# Topic Correlation
mod.out.corr<-topicCorr(model)
plot.topicCorr(mod.out.corr)

# Estimate Covariate Effects
prep <- estimateEffect(1:15 ~ REGION+s(YEAR),model,meta=meta,uncertainty="Global",documents=docs)

# Topics over time
plot.estimateEffect(prep,covariate="YEAR",method="continuous",topics=c(14, 3),printlegend=TRUE,xlab="Year",xlim=c(1980,2014),main = "Comparing Topics over Time",labeltype="custom",custom.labels=c("Religion", "Public Health"),ylim=c(0,.25),nsims=200)

# topics over region
regions = c("Asia","EECA","MENA","Africa","West","LA")
plot.estimateEffect(prep,"REGION",method="pointestimate",topics=9,printlegend=TRUE,labeltype="custom",custom.labels=regions,main="Women's Rights",ci.level=.95,nsims=100)
```
